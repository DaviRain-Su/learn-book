# MPI tutorials

并行计算, 消息传递接口MPI采取了正确的途径来扩展有关并行编程的
知识，尽管MPI的级别比大多数并行编程库低，但是他是构建并行编程知识的良好基础。

如何轻松构建或访问自己的集群的资源。

获得有关编写并行应用程序的基本接口的信息

库最常采用的模型是消息传递模型。

消息传递模型？这意味者应用程序在进程之间传递消息以及执行任务。

例如主流程可以通过向从属流程传递描述工作的消息来将工作分配给从属流程。
另一个示例是并行合并排序应用程序，该应用程序在本地对进程中的数据进行排序，
然后将结果传递给相邻进程以合并已排序的列表。

消息传递模型几乎可以表示任何并行应用程序。

MPI只是接口的定义，然后又开发人员为各自的体系结构创建接口的实现。

## MPI的消息传递模型设计

传播者的概念，通信器定义了一组能够相互通信的过程，在这组过程中，
每个过程都分配有一个唯一的等级，并且他们通过等级明确地彼此通信。

通信的基础建立在进程之间的发送和接收操作上，进程可以通过提供进程的等级和唯一
的标签来标示消息，从而将消息发送到另一个进程。然后，接受者可以发布带有给定标签
的消息的接收（或者甚至可能不在乎该标签），然后相应地处理数据。这样的涉及一个发送者
和接收者的通信被称为点对点通信。

在许多情况下，流程可能需要与其他人进行沟通。例如，当主进程需要向其所有工作进程广播信息时。
在这种情况下，编写完成所有发送和接收的代码将很麻烦。实际上，他通常不会以
最佳方式使用网络。MPI可以处理涉及所有流程的各种类型的集体通信。

点对点通信和集体通信的混合可用于创建高度复杂的并行程序。
实际上，此功能时如此的强大，以至于甚至没有必要尅是描述MPI的高级机制。

# MPI Hello world

包括如何初始化MPI的基础内容 以及让MPI任务跑在几个不同的进程上。

    MPI 环境必须使用： MPI_Init(int *argcm char*** argv);

对MPI_Init来说，一个通讯器communicator会根据所有可用的进程被创建出来,
MPI_Init接受的两个参数是没有用处的，不过参数的位置保留着，可能以后的实现
会需要用到。

    MPI_Comm_size(MPI_Comm_communicator, int* size);
MPI_Comm_size 会返回communicator的大小，也就是communicator中可用的进程数量。
在这个实例中，MPI_COMM_WORLD 这个communicator 是MPI帮我们生成的。这个变量包含了当前
MPI任务中所有的进程，因此在我们的代码里面这个调用会返回所有的可用的进程数量。

    MPI_Comm_rank(MPI_Comm communicator, int* rank);

MPI_Comm_rank 这个函数会返回communicator中级进程的等级。
communicator中级进程会依次得到一个从0开始递增的数字作为等级值、
rank值主要是制定发送或者接受信息时对应的进程。

    MPI_Get_processor_name(char* name, int* name_length);

MPI_Get_processror_name会得到当前进展实际跑的时候所在的处理器名字。

    MPI_FInalize()
MPI_Finalize用来清理MPI环境。调用之后就没有MPI函数可以被调用。
    如果需要在好几个上面的副本上面运行这个MPI程序的话，需要配置一个主机文件
    /etc/hosts.

如果在节点群集上运行MPI程序，则必须设置一个主机文件。
如果只是在便携式计算机或者单台计算机上运行mpi，则可以忽略。

主机文件中包含了将在其上执行MPI作业的所有计算机的名称。
为了便于执行，应确保所有这些计算机都具有ssh访问权限，并且还应设置一个授权密钥文件。
以避免出现ssh的密码提示。


